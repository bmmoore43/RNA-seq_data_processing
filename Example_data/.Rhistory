cat.dist = 0.03
);
venn.plot <- draw.quad.venn(
area1 = 435,
area2 = 2661,
area3 = 751,
area4 = 1915,
n12 = 246,
n13 = 67,
n23 = 221,
n14 = 126,
n24 = 858,
n34 = 312,
n123 = 27,
n124 = 73,
n134 = 43,
n234 = 120,
n1234 = 18,
category = c("GO SM-genes", "GO PM-genes", "Aracyc SM-genes", "Aracyc PM-genes"),
fill = c("cornflowerblue", "green", "yellow", "darkorchid1"),
lty = "blank",
cex = 1,
cat.cex = 1.25,
cat.col = c("darkblue", "darkgreen", "orange", "darkorchid4"),
cat.dist = 0.1
);
venn.plot <- draw.quad.venn(
area1 = 435,
area2 = 2661,
area3 = 751,
area4 = 1915,
n12 = 246,
n13 = 67,
n23 = 221,
n14 = 126,
n24 = 858,
n34 = 312,
n123 = 27,
n124 = 73,
n134 = 43,
n234 = 120,
n1234 = 18,
category = c("GO SM-genes", "GO PM-genes", "Aracyc SM-genes", "Aracyc PM-genes"),
fill = c("cornflowerblue", "green", "yellow", "darkorchid1"),
lty = "blank",
cex = 1,
cat.cex = 1.25,
cat.col = c("darkblue", "darkgreen", "orange", "darkorchid4"),
cat.dist = 0.1
);
p <- 0.675125117 #pseudogene rate
x1 <- runif(1000, 0, 1)
x2 <- c()
ind <- 1:length(x1)
for(i in ind){
if(x1[i] <= p){x2[i] <- 0}
else if(x1[i] > p){x2[i] <- 1}}
x2
1000/3
y <-sample(x2, 2, replace = FALSE, prob = NULL)
y
y <-sample(x2, 2, replace = FALSE, prob = NULL)
y
type(y)
if(y==0,0){print(y)}
if(y==c(0,0)){print(y)}
if(y=c(0,0)){print(y)}
if(y = c(0,0)){print(y)}
if(y == c(0,0)){print(y)}
y
if(y[1] == 0{print(y)}
if(y[1] == 0){print(y)}
if((y[1] == 0)&(y[2] == 0)){print(y)}
ind2 <- 1:1000
for(i in ind2){y <-sample(x2, 2, replace = FALSE, prob = NULL)
if((y[1] == 0)&(y[2] == 0)){print(y)}
else if((y[1] == 0)&(y[2] == 1)){print(y)}
else if((y[1] == 1)&(y[2] == 0)){print(y)}
else if((y[1] == 1)&(y[2] == 1)){print(y)}}
for(i in ind2){y <-sample(x2, 2, replace = FALSE, prob = NULL)
if((y[1] == 0)&(y[2] == 0)){print(y)}
else if((y[1] == 0)&(y[2] == 1)){print(y), l[[i]] <- 1}
else if((y[1] == 1)&(y[2] == 0)){print(y)}
else if((y[1] == 1)&(y[2] == 1)){print(y)}}
for(i in ind2){y <-sample(x2, 2, replace = FALSE, prob = NULL)
if((y[1] == 0)&(y[2] == 0)){print(y)}
else if((y[1] == 0)&(y[2] == 1)){l[[i]] <- 1}
else if((y[1] == 1)&(y[2] == 0)){print(y)}
else if((y[1] == 1)&(y[2] == 1)){print(y)}}
l <- list()
for(i in ind2){y <-sample(x2, 2, replace = FALSE, prob = NULL)
if((y[1] == 0)&(y[2] == 0)){print(y)}
else if((y[1] == 0)&(y[2] == 1)){l[[i]] <- 1}
else if((y[1] == 1)&(y[2] == 0)){print(y)}
else if((y[1] == 1)&(y[2] == 1)){print(y)}}
l <- c()
for(i in ind2){y <-sample(x2, 2, replace = FALSE, prob = NULL)
if((y[1] == 0)&(y[2] == 0)){print(y)}
else if((y[1] == 0)&(y[2] == 1)){l[[i]] <- 1}
else if((y[1] == 1)&(y[2] == 0)){print(y)}
else if((y[1] == 1)&(y[2] == 1)){print(y)}}
l
l <- c()
for(i in ind2){y <-sample(x2, 2, replace = FALSE, prob = NULL)
if((y[1] == 0)&(y[2] == 0)){print(y)}
else if((y[1] == 0)&(y[2] == 1)){l[[i]] <- 'b'}
else if((y[1] == 1)&(y[2] == 0)){print(y)}
else if((y[1] == 1)&(y[2] == 1)){print(y)}}
for(i in ind2){y <-sample(x2, 2, replace = FALSE, prob = NULL)
if((y[1] == 0)&(y[2] == 0)){l[[i]] <- 'a'}
else if((y[1] == 0)&(y[2] == 1)){l[[i]] <- 'b'}
else if((y[1] == 1)&(y[2] == 0)){l[[i]] <- 'b'}
else if((y[1] == 1)&(y[2] == 1)){l[[i]] <- 'c'}}
l
r<-rmultinom(10, size = 12, prob = c(0.1,0.2,0.8))
r
l <- c()
for(i in ind2){y <-sample(x2, 2, replace = FALSE, prob = NULL)
if((y[1] == 0)&(y[2] == 0)){l[[i]] <- 1}
else if((y[1] == 0)&(y[2] == 1)){l[[i]] <- 2}
else if((y[1] == 1)&(y[2] == 0)){l[[i]] <- 2}
else if((y[1] == 1)&(y[2] == 1)){l[[i]] <- 3}}
l
for(i in ind2){y <-sample(x2, 2, replace = FALSE, prob = NULL)
if((y[1] == 0)&(y[2] == 0)){l[[i]] <- as.factor(1)}
else if((y[1] == 0)&(y[2] == 1)){l[[i]] <- 2}
else if((y[1] == 1)&(y[2] == 0)){l[[i]] <- 2}
else if((y[1] == 1)&(y[2] == 1)){l[[i]] <- 3}}
l
for(i in ind2){y <-sample(x2, 2, replace = FALSE, prob = NULL)
if((y[1] == 0)&(y[2] == 0)){l[[i]] <- as.factor(1)}
else if((y[1] == 0)&(y[2] == 1)){l[[i]] <- as.factor(2)}
else if((y[1] == 1)&(y[2] == 0)){l[[i]] <- as.factor(2)}
else if((y[1] == 1)&(y[2] == 1)){l[[i]] <- as.factor(3)}}
l
for(i in ind2){y <-sample(x2, 2, replace = FALSE, prob = NULL)
if((y[1] == 0)&(y[2] == 0)){l[[i]] <- 1}
else if((y[1] == 0)&(y[2] == 1)){l[[i]] <- 2}
else if((y[1] == 1)&(y[2] == 0)){l[[i]] <- 2}
else if((y[1] == 1)&(y[2] == 1)){l[[i]] <- 3}}
l
count1 <- length(which(l == 1))
count2 <- length(which(l == 2))
count2 <- length(which(l == 3))
count2 <- length(which(l == 2))
count3 <- length(which(l == 3))
count3
all <- length(ind2)
all <- length(ind2)
prob1 <- count1/all
prob1 <- count1/all
prob2 <- count2/all
prob3 <- count3/all
probs <- c(prob1, prob2, prob3)
probs
comp = 1-sum(probs)
comp
chisq.test(x=c(1059,82,104), p=probs)
chisq.test(x=c(349,1063,3079), p=probs)
df<- r(w,z)
w <-c(1059,82,104)
z<- c(349,1063,3079)
df<- rbind(w,z)
View(df)
chisq.test(df, p=probs)
test1 <-chisq.test(x=c(1059,82,104), p=probs)
summary(test1)
library(VennDiagram)
venn.plot <- draw.quad.venn(
area1 = 426, #combined SM
area2 = 2290, #combined PM
area3 = 47, #gold SM
area4 = 348, #gold PM
n12 = 0,
n13 = 0,
n23 = 22,
n14 = 65,
n24 = 0,
n34 = 0,
n123 = 0,
n124 = 0,
n134 = 0,
n234 = 0,
n1234 = 0,
category = c("combined SM-genes", "combined PM-genes", "benchmark SM-genes", "benchmark PM-genes"),
fill = c("cornflowerblue", "green", "yellow", "darkorchid1"),
lty = "blank",
cex = 1,
cat.cex = 1.25,
cat.col = c("darkblue", "darkgreen", "orange", "darkorchid4"),
cat.dist = 0.1
);
install.packages('devtools')
library(devtools)
install_github('andreacirilloac/updateR')
library(updateR)
install.packages("tibble")
install.packages(c("bindrcpp", "curl", "digest", "lme4", "MASS", "mgcv", "mvtnorm", "nlme", "openssl", "plogr", "quantreg", "Rcpp", "RcppEigen", "rlang", "rpart", "selectr", "stringi", "stringr", "tidyselect", "VennDiagram", "xml2", "yaml"))
library("devtools", lib.loc="/Library/Frameworks/R.framework/Versions/3.3/Resources/library")
install_github('andreacirilloac/updateR')
install.packages("tibble")
library("git2r", lib.loc="/Library/Frameworks/R.framework/Versions/3.3/Resources/library")
install.packages("tibble")
install.packages(c("bindrcpp", "curl", "digest", "lme4", "MASS", "mgcv", "mvtnorm", "nlme", "openssl", "quantreg", "Rcpp", "RcppEigen", "rlang", "rpart", "stringi", "stringr", "tidyselect", "xml2", "yaml"))
Sys.getenv("TZ")
Sys.setenv(TZ="America/Detroit")
Sys.getenv("TZ")
as.POSIXct(t, tz=getOption("tz"))
as.POSIXct(t, tz=getOption("TZ"))
as.POSIXct(t, TZ=getOption("TZ"))
library(devtools)
install_github('andreacirilloac/updateR')
install.packages("rlang")
install.packages("rlang")
xcode-select --install
xcode-select --reset
citation("ComplexHeatmap")
install.packages("ggtern")
options(tz="America/New_York")
install.packages("ggtern")
Sys.setenv(TZ="America/New_York")
Sys.getenv("TZ")
as.POSIXct(t, tz=getOption("tz"))
install.packages("ggtern")
library("ggtern", lib.loc="/Library/Frameworks/R.framework/Versions/3.3/Resources/library")
Sys.getenv("TZ")
install.packages("ggtern")
Sys.setenv(TZ="America/New_York")
Sys.getenv("TZ")
install.packages("compositions")
Sys.getenv()
Sys.getenv()
Sys.getenv("TZ")
#Assume a balanced design simply for convenience of data generation.  Assume 20 populations are sampled for their density values in each of the three regions.
n.groups = 3
n.sample = 20
#Total number of data points
n = n.groups*n.sample
#Specify a vector that acts as an indicator of region (1,2,3) for each population
x = c(1,2,3)       # Create a vector with values of 1,2,3 by region
reg = factor(x, labels=c("reg1","reg2","reg3")) #Translate the vector into factors
#Assume the resource varies randomly between 45 - 70 at the location of each population
resource =  rnorm(n, c(45:70))
resource
#Build the design matrix of the interactive combination of reg and population
#factor levels
region <-gl(n=n.groups,k=n.sample,length=n)
Xmat = as.matrix(model.matrix(~region*resource))
Xmat
#Chose the values for the parameters defined in Question 1
beta.vec =  c(-250, 150, 200, 6, -3, -4)
#Generate the linear predictor
lin.pred =  as.numeric(as.matrix(Xmat)%*%as.matrix(beta.vec))
lin.pred
#Specify the residuals assuming that the SD = 10
sigma <- 10
eps <-rnorm(n,0,sigma)
#Put together the dependent data where the response is a combination of the deterministic and error terms
density <-as.numeric(as.matrix(Xmat)%*%as.matrix(beta.vec)+eps)
#density <-as.numeric(lin.pred+eps)
density
#Print the design matrix for generating the data and the error values
Xmat
eps
hist(density)
#The data are not normally distributed
#ANCOVA does not require normally distributed data, only normally distributed residuals
library("lattice") # Load the lattice library
xyplot(density ~resource|region,ylab="Density",xlab="Resource level",main=
"Region-specific relationship between population density and resource level",layout=c(3,1), groups = factor(region,labels=c("reg1","reg2","reg3")))
fit.ancova = lm(density ~region*resource)
fit.ancova
fit.ancova.sum<-summary(fit.ancova)
fit.ancova.sum
#design matrix:
Xmat
#parameter estimates:
lin.pred
#compare to beta.vec:
beta.vec
#slopes are:
#for region 1: use resource coefficient: 6.0776
slopereg1=6.0776
slopereg1
#for region 2: use resource + region2:resource: 6.0776-3.3431 =2.7345
slopereg2=6.0776-3.3431
slopereg2
#for region 3: use resource + region3:resource: 6.0776-4.1610 =1.9166
slopereg3=6.0776-4.1610
slopereg3
library(ggplot2)
data.df <- data.frame(Density = density, Region =region, Resource = resource)
p <- ggplot(data.df, aes(Resource, Density, color = Region)) + geom_point()+ xlab("Resource") + ylab("Pop Density") + ggtitle("Population density by region")
p
p+ geom_smooth(aes(group=Region), method="lm", fullrange=TRUE)
fit.main.ancova = lm(density ~region + resource)
fit.main.ancova
summary(fit.main.ancova)
#design matrix 2- no interactions
Xmat2<-model.matrix(fit.main.ancova)
#Xmat2 = as.matrix(model.matrix(~region+resource))
Xmat2
#slope is just the resouce, 3.084. This makes sense because it is close in value to the average of the 3 individual slopes of each region, and we are taking all 3 regions into account. It is slightly different due to the random error
slopeall= (slopereg1+slopereg2+slopereg3)/3
slopeall
slopemain= 3.084
p2 <- ggplot(data.df, aes(Resource, Density)) + geom_point(aes(colour = Region))+ xlab("Resource") + ylab("Pop Density") + ggtitle("Population density by resource")
p2
p2+ geom_smooth(method="lm", fullrange=TRUE)
#for the fit of the model, the R squared is lower (0.7028) than the previous interactive model (0.8875), meaning there is more unexplained variance in the main effects model. Also you can see in the plot that at higher resource levels, the variance is greater. You can also see in the interactive model that for each region, the slope is significantly different. Therefore the interactive model is the better model.
#data simulation
n.iter <-1000 # Desired number of iterations
estimates <-array(dim=c(n.iter,length(beta.vec))) #Data structure to hold results
#iterations for interactive model
for(i in 1:n.iter){  #Run simulation n.iter times
eps <- rnorm(n,0,sigma) #Residuals
y <- as.numeric(as.matrix(Xmat)%*%as.matrix(beta.vec)+eps) #Assemble data
fit.model <- lm(y ~region*resource)  #Break down data
estimates[i,] <- fit.model$coefficients  #Save estimates of coefs.
}
print(apply(estimates,2,mean),dig=2)
#iterations allow for the mean of the estimates to get closer to the actual values of the beta vector
#iterations for main model
beta.vec2 <- c(-250, 150, 200, 6)
for(i in 1:n.iter){  #Run simulation n.iter times
eps <- rnorm(n,0,sigma) #Residuals
y <- as.numeric(as.matrix(Xmat2)%*%as.matrix(beta.vec2)+eps) #Assemble data
fit.model <- lm(y ~region+resource)  #Break down data
estimates[i] <- fit.model$coefficients  #Save estimates of coefs.
}
print(apply(estimates,2,mean),dig=2)
#not sure why I'm getting warnings here?
install.packages("swirl")
# First we need to install EdgeR
source("http://bioconductor.org/biocLite.R")
biocLite("edgeR")
biocLite("edgeR")
library(edgeR)
detach("package:methods", unload=TRUE)
library("methods", lib.loc="/Library/Frameworks/R.framework/Versions/3.5/Resources/library")
library("limma", lib.loc="/Library/Frameworks/R.framework/Versions/3.5/Resources/library")
remove.packages("limma")
install.packages("limma")
biocLite(limma)
install.packages("limma")
library(edgeR)
source("https://bioconductor.org/biocLite.R")
biocLite()
biocLite(limma)
biocLite()
biocLite(limma)
biocLite(c("GenomicFeatures", "AnnotationDbi"))
if(!require(installr)) {
install.packages("installr");
require(installr)
}
biocLite("limma")
biocLite("edgeR")
biocLite("edgeR", type="binary")
library(edgeR)
biocLite()
library("Biobase", lib.loc="/Library/Frameworks/R.framework/Versions/3.5/Resources/library")
detach("package:Biobase", unload=TRUE)
remove.packages("Biobase")
source("https://bioconductor.org/biocLite.R")
obs <- 1:5
mod <- c(0.8,2.4,2,3,4.8)
df <- data.frame(obs, mod)
R2 <- rsq(df)
rsq <- function (x, y) cor(x, y) ^ 2
R2 <- rsq(obs, mod)
print(R2)
View(df)
p.a <-ggplot(df, aes(x =obs,  y=mod, color=obs)) +
geom_point() +  #scale_color_manual(values = c("turquoise3", "indianred2", "blueviolet")) +
theme(axis.text.x  = element_text(vjust=0.5, colour= "black", size= rel(1)))
library(ggplot2)
p.a <-ggplot(df, aes(x =obs,  y=mod, color=obs)) +
geom_point() +  #scale_color_manual(values = c("turquoise3", "indianred2", "blueviolet")) +
theme(axis.text.x  = element_text(vjust=0.5, colour= "black", size= rel(1)))
p.a
x<- dim(df)
x
j<- x[1]
j<- as.numeric(x[1])
obs2 <- c(0,0.1,1.2,0.5,0.6)
mod2 <- c(0,0,1,1,1)
df2<- data.frame(obs2, mod2)
View(df2)
poisson.t.test <- glm(df2$obs2 ~ df2$mod2, family = poisson)
summary(poisson.t.test)
hist(obs2)
gamma.glm <- glm(df2$obs2 ~ df2$mod2, family =Gamma)
norm.glm <- glm(df2$obs2 ~ df2$mod2, family =normal)
norm.glm <- glm(df2$obs2 ~ df2$mod2) #family =normal
summary(norm.glm)
poiss.glm <- glm(df2$obs2 ~ df2$mod2, family =poisson)
summary(poiss.glm)
#df <- data.frame(obs, mod)
rsq <- function (x, y) cor(x, y) ^ 2
R2 <- rsq(obs2, mod2)
R2
bc<-biserial.cor(obs2, mod2)#, use = c("all.obs", "complete.obs"), level = 1)
install.packages("ltm")
library(ltm)
bc<-biserial.cor(obs2, mod2)#, use = c("all.obs", "complete.obs"), level = 1)
bc
bc2 <- bc^2
corrPCC <- cor(obs2, mod2)
### Correlation
cor(l, l2)
### Making and working with lists
l <- c(1, 2, 5, 5, 1, 7)
l2 <- l*10
### Correlation
cor(l, l2)
# What if we just get a random list of 6 numbers between 1 and 10?
l3 <- sample(1:10, 6, replace=T)
cor(l, l3)
12**0.5
15**0.5
...
library(devtools)
install_github
install_github("johnplloyd/R_packages/lloydUtils")
?corner
library(lloydUtils)
?corner
install.packages("roxygen2")
library(affy)
install.packages("affy")
if (!requireNamespace("BiocManager", quietly = TRUE))
install.packages("BiocManager")
BiocManager::install("affy")
library(affy)
browseVignettes('affy')
citation("affy")
version("affy")
library(limma)
BiocManager::install("limma")
library(limma)
log10(4.2123)
log10(2.0485)
log10(17.4897)
###################################
# Differential expression (edgeR) #
###################################
# install edgeR
if (!require("BiocManager", quietly = TRUE))
install.packages("BiocManager")
BiocManager::install("edgeR")
Yesy
Yes
###################################
# Differential expression (edgeR) #
###################################
# install edgeR
if (!require("BiocManager", quietly = TRUE))
install.packages("BiocManager")
BiocManager::install("edgeR")
# load the package and data
# Run every time to you start a new R session.
library(edgeR)
setwd("~/Desktop/Github/RNA-seq_data_processing/Example_data")
# Download the expression data
counts <- read.table('counts_data.csv', header=T, row.names='gene', sep=',')
head(counts)
summary(counts$control_1) # Get a summary of the expression levels for the first replicate of the control treatment
treatments <- c("C","C","C","Cold","Cold","Cold") # you are making a new list called "group" using c() of your treatments
# I think this can be read in as a table
d <- DGEList(counts, group=treatments, genes=rownames(counts)) # rownames(counts) tells DGEList that the gene names are rownames in your counts dataframe
# d is now the variable that contains your DGEList
# You can visualize the frequency distribution of your counts in your samples using a histogram.
# Due to the large variability in counts per gene it is useful to use the log transform counts for normalization.
hist(d$counts, breaks = 50, xlab = "Counts")
hist(log2(d$counts), xlim=c(0, 20), breaks=50, xlab = "LogCounts")
# Normalize between samples
# The goal is to normalize the counts across samples so that MOST genes have the same abundance across the different samples.
# The idea is that while you expect some genes will be differentially expressed across the datasets, most genes will not be affected
# by your treatment. We can use those "unchanging" genes to normalize between the samples.
d <- calcNormFactors(d) #This calculates the effective library size and normalization factors.
d$samples
# Estimate the dispersion (i.e. the BCV between biological replicates).
d <- estimateCommonDisp(d)
d <- estimateTagwiseDisp(d)
# The Fisher's exact test takes into account the "Tagwise Dispersian" when calculating the p-value
c_vs_cold <- exactTest(d, pair=c('C','Cold'))
# Since we are calculating significance for thousands of genes, we need to use false discovery rate correction
# Here we use the Benjamini-Hochberg (BH) method (BH) to correct the p-values, the correct p-values are called q-values.
# We are saving the corrected p-values in a new column in the c_vs_cold$table called "FDR"
c_vs_cold$table$FDR <- p.adjust(c_vs_cold$table$PValue, method='BH')
# Select the genes that are significantly differentially expressed (q-value <= 0.05) and have a logFC > 2 or < -2
c_vs_cold_genes <- subset(c_vs_cold$table, c_vs_cold$table$FDR <= 0.05 & abs(c_vs_cold$table$logFC) >=2)
View(c_vs_cold_genes)
# Check out the relationship between logFC and significance by making a "volcano" plot:
plot(-log(c_vs_cold_genes$FDR)~c_vs_cold_genes$logFC,
ylab= "logFDR",
xlab = "logFC")
# Save your results (you do not need to turn these in, but you may want to refer to these results later)
write.table(c_vs_cold$table,file="Control_vs_Cold.txt",quote=FALSE,sep="\t",row.names=TRUE) #quote=FALSE, to remove the "" that are automatically added on.
View(c_vs_cold_genes)
write.table(c_vs_cold_genes,file="Control_vs_Cold_DEgenes.txt",quote=FALSE,sep="\t",row.names=TRUE)
View(counts)
# Save your results (you do not need to turn these in, but you may want to refer to these results later)
write.table(c_vs_cold$table,file="Control_vs_Cold.txt",quote=FALSE,sep="\t",row.names='gene') #quote=FALSE, to remove the "" that are automatically added on.
write.table(data.frame("gene"=rownames(c_vs_cold$table),s_cold$table),file="Control_vs_Cold.txt",quote=FALSE,sep="\t",row.names=FALSE) #quote=FALSE, to remove the "" that are automatically added on.
write.table(data.frame("gene"=rownames(c_vs_cold$table),c_vs_cold$table),file="Control_vs_Cold.txt",quote=FALSE,sep="\t",row.names=FALSE) #quote=FALSE, to remove the "" that are automatically added on.
# Select the genes that are significantly differentially expressed (q-value <= 0.05) and have a logFC > 2 or < -2
c_vs_cold_genes <- subset(c_vs_cold$table, c_vs_cold$table$FDR <= 0.05 & abs(c_vs_cold$table$logFC) >=2)
write.table(data.frame("gene"=rownames(c_vs_cold_genes),c_vs_cold_genes),file="Control_vs_Cold_DEgenes.txt",quote=FALSE,sep="\t",row.names=FALSE)
View(c_vs_cold_genes)
write.table(data.frame("gene"=rownames(c_vs_cold_genes),c_vs_cold_genes),file="Control_vs_Cold_DEgenes.txt",quote=FALSE,sep="\t",row.names=FALSE)
